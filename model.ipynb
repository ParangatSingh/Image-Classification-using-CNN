{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\divy2\\Desktop\\ImageClassification\\mnist_cnn_env\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, callbacks\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Dataset Loading and Exploration\n",
    "def load_and_explore_data():\n",
    "    print(\"Loading MNIST dataset...\")\n",
    "    (X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "    \n",
    "    # Display dataset information\n",
    "    print(f\"Training set shape: {X_train.shape}\")\n",
    "    print(f\"Test set shape: {X_test.shape}\")\n",
    "    \n",
    "    # Visualize sample images\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    for i in range(10):\n",
    "        plt.subplot(2, 5, i+1)\n",
    "        plt.imshow(X_train[i], cmap='gray')\n",
    "        plt.title(f\"Label: {y_train[i]}\")\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('sample_images.png')\n",
    "    plt.close()\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Data Preprocessing\n",
    "def preprocess_data(X_train, y_train, X_test, y_test):\n",
    "    # Normalize pixel values\n",
    "    X_train = X_train.astype('float32') / 255\n",
    "    X_test = X_test.astype('float32') / 255\n",
    "    \n",
    "    # Reshape for CNN (add channel dimension)\n",
    "    X_train = X_train.reshape((-1, 28, 28, 1))\n",
    "    X_test = X_test.reshape((-1, 28, 28, 1))\n",
    "    \n",
    "    # Convert labels to one-hot encoding\n",
    "    y_train = to_categorical(y_train, 10)\n",
    "    y_test = to_categorical(y_test, 10)\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Data Augmentation\n",
    "def create_data_augmentation():\n",
    "    return tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "        rotation_range=10,\n",
    "        zoom_range=0.1,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Build CNN Model\n",
    "def build_model():\n",
    "    model = models.Sequential([\n",
    "        # First Convolutional Block\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.25),\n",
    "        \n",
    "        # Second Convolutional Block\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.25),\n",
    "        \n",
    "        # Third Convolutional Block\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.25),\n",
    "        \n",
    "        # Flatten and Dense Layers\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    " #5. Training Callbacks\n",
    "def create_callbacks():\n",
    "    return [\n",
    "        callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=5,\n",
    "            restore_best_weights=True\n",
    "        ),\n",
    "        callbacks.ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.2,\n",
    "            patience=3,\n",
    "            min_lr=1e-6\n",
    "        ),\n",
    "        callbacks.TensorBoard(\n",
    "            log_dir=f'logs/{datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")}',\n",
    "            histogram_freq=1\n",
    "        )\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Plot Training History\n",
    "def plot_training_history(history):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Plot accuracy\n",
    "    ax1.plot(history.history['accuracy'])\n",
    "    ax1.plot(history.history['val_accuracy'])\n",
    "    ax1.set_title('Model Accuracy')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Accuracy')\n",
    "    ax1.legend(['Train', 'Validation'])\n",
    "    \n",
    "    # Plot loss\n",
    "    ax2.plot(history.history['loss'])\n",
    "    ax2.plot(history.history['val_loss'])\n",
    "    ax2.set_title('Model Loss')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Loss')\n",
    "    ax2.legend(['Train', 'Validation'])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('training_history.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Evaluate Model\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    # Get predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "    y_test_classes = np.argmax(y_test, axis=1)\n",
    "    \n",
    "    # Calculate and print metrics\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test_classes, y_pred_classes))\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    cm = confusion_matrix(y_test_classes, y_pred_classes)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.savefig('confusion_matrix.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading MNIST dataset...\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11490434/11490434 [==============================] - 3s 0us/step\n",
      "Training set shape: (60000, 28, 28)\n",
      "Test set shape: (10000, 28, 28)\n",
      "WARNING:tensorflow:From c:\\Users\\divy2\\Desktop\\ImageClassification\\mnist_cnn_env\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\divy2\\Desktop\\ImageClassification\\mnist_cnn_env\\lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\divy2\\Desktop\\ImageClassification\\mnist_cnn_env\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "\n",
      "Model Summary:\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 26, 26, 32)        128       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 13, 13, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 13, 13, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 11, 11, 64)        256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 5, 5, 64)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 5, 5, 64)          0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 3, 3, 64)          36928     \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 3, 3, 64)          256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 1, 1, 64)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 1, 1, 64)          0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               8320      \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 128)               512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66506 (259.79 KB)\n",
      "Trainable params: 65930 (257.54 KB)\n",
      "Non-trainable params: 576 (2.25 KB)\n",
      "_________________________________________________________________\n",
      "\n",
      "Training model...\n",
      "Epoch 1/25\n",
      "WARNING:tensorflow:From c:\\Users\\divy2\\Desktop\\ImageClassification\\mnist_cnn_env\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\divy2\\Desktop\\ImageClassification\\mnist_cnn_env\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "1875/1875 [==============================] - 72s 35ms/step - loss: 0.7301 - accuracy: 0.7699 - val_loss: 0.0917 - val_accuracy: 0.9718 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "1875/1875 [==============================] - 62s 33ms/step - loss: 0.3125 - accuracy: 0.9050 - val_loss: 0.1048 - val_accuracy: 0.9660 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "1875/1875 [==============================] - 59s 32ms/step - loss: 0.2508 - accuracy: 0.9243 - val_loss: 0.0581 - val_accuracy: 0.9808 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "1875/1875 [==============================] - 60s 32ms/step - loss: 0.2227 - accuracy: 0.9336 - val_loss: 0.0557 - val_accuracy: 0.9821 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "1875/1875 [==============================] - 63s 34ms/step - loss: 0.2015 - accuracy: 0.9397 - val_loss: 0.0473 - val_accuracy: 0.9854 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "1875/1875 [==============================] - 62s 33ms/step - loss: 0.1872 - accuracy: 0.9429 - val_loss: 0.0499 - val_accuracy: 0.9838 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "1875/1875 [==============================] - 60s 32ms/step - loss: 0.1764 - accuracy: 0.9474 - val_loss: 0.0443 - val_accuracy: 0.9863 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "1875/1875 [==============================] - 60s 32ms/step - loss: 0.1728 - accuracy: 0.9478 - val_loss: 0.0403 - val_accuracy: 0.9857 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "1875/1875 [==============================] - 60s 32ms/step - loss: 0.1654 - accuracy: 0.9508 - val_loss: 0.0395 - val_accuracy: 0.9866 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "1875/1875 [==============================] - 60s 32ms/step - loss: 0.1596 - accuracy: 0.9517 - val_loss: 0.0414 - val_accuracy: 0.9863 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "1875/1875 [==============================] - 59s 32ms/step - loss: 0.1575 - accuracy: 0.9531 - val_loss: 0.0432 - val_accuracy: 0.9852 - lr: 0.0010\n",
      "Epoch 12/25\n",
      "1875/1875 [==============================] - 61s 32ms/step - loss: 0.1539 - accuracy: 0.9541 - val_loss: 0.0365 - val_accuracy: 0.9883 - lr: 0.0010\n",
      "Epoch 13/25\n",
      "1875/1875 [==============================] - 66s 35ms/step - loss: 0.1480 - accuracy: 0.9556 - val_loss: 0.0357 - val_accuracy: 0.9884 - lr: 0.0010\n",
      "Epoch 14/25\n",
      "1875/1875 [==============================] - 63s 33ms/step - loss: 0.1459 - accuracy: 0.9560 - val_loss: 0.0399 - val_accuracy: 0.9872 - lr: 0.0010\n",
      "Epoch 15/25\n",
      "1875/1875 [==============================] - 70s 37ms/step - loss: 0.1460 - accuracy: 0.9560 - val_loss: 0.0356 - val_accuracy: 0.9882 - lr: 0.0010\n",
      "Epoch 16/25\n",
      "1875/1875 [==============================] - 61s 32ms/step - loss: 0.1413 - accuracy: 0.9570 - val_loss: 0.0374 - val_accuracy: 0.9885 - lr: 0.0010\n",
      "Epoch 17/25\n",
      "1875/1875 [==============================] - 61s 33ms/step - loss: 0.1403 - accuracy: 0.9589 - val_loss: 0.0361 - val_accuracy: 0.9876 - lr: 0.0010\n",
      "Epoch 18/25\n",
      "1875/1875 [==============================] - 59s 31ms/step - loss: 0.1352 - accuracy: 0.9597 - val_loss: 0.0358 - val_accuracy: 0.9876 - lr: 0.0010\n",
      "Epoch 19/25\n",
      "1875/1875 [==============================] - 59s 31ms/step - loss: 0.1277 - accuracy: 0.9622 - val_loss: 0.0321 - val_accuracy: 0.9888 - lr: 2.0000e-04\n",
      "Epoch 20/25\n",
      "1875/1875 [==============================] - 59s 32ms/step - loss: 0.1229 - accuracy: 0.9623 - val_loss: 0.0301 - val_accuracy: 0.9904 - lr: 2.0000e-04\n",
      "Epoch 21/25\n",
      "1875/1875 [==============================] - 59s 32ms/step - loss: 0.1184 - accuracy: 0.9652 - val_loss: 0.0306 - val_accuracy: 0.9895 - lr: 2.0000e-04\n",
      "Epoch 22/25\n",
      "1875/1875 [==============================] - 59s 32ms/step - loss: 0.1192 - accuracy: 0.9632 - val_loss: 0.0302 - val_accuracy: 0.9899 - lr: 2.0000e-04\n",
      "Epoch 23/25\n",
      "1875/1875 [==============================] - 59s 31ms/step - loss: 0.1187 - accuracy: 0.9646 - val_loss: 0.0310 - val_accuracy: 0.9895 - lr: 2.0000e-04\n",
      "Epoch 24/25\n",
      "1875/1875 [==============================] - 59s 32ms/step - loss: 0.1150 - accuracy: 0.9653 - val_loss: 0.0300 - val_accuracy: 0.9902 - lr: 4.0000e-05\n",
      "Epoch 25/25\n",
      "1875/1875 [==============================] - 59s 32ms/step - loss: 0.1153 - accuracy: 0.9652 - val_loss: 0.0298 - val_accuracy: 0.9900 - lr: 4.0000e-05\n",
      "\n",
      "Evaluating model...\n",
      "313/313 [==============================] - 3s 9ms/step\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       980\n",
      "           1       1.00      0.99      0.99      1135\n",
      "           2       0.99      0.98      0.98      1032\n",
      "           3       0.98      1.00      0.99      1010\n",
      "           4       0.99      0.99      0.99       982\n",
      "           5       0.99      0.99      0.99       892\n",
      "           6       0.99      0.99      0.99       958\n",
      "           7       0.98      0.99      0.98      1028\n",
      "           8       0.99      0.99      0.99       974\n",
      "           9       0.99      0.99      0.99      1009\n",
      "\n",
      "    accuracy                           0.99     10000\n",
      "   macro avg       0.99      0.99      0.99     10000\n",
      "weighted avg       0.99      0.99      0.99     10000\n",
      "\n",
      "\n",
      "Saving model...\n",
      "Model saved as 'mnist_cnn_model.h5'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\divy2\\Desktop\\ImageClassification\\mnist_cnn_env\\lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def main():\n",
    "    # 1. Load and explore data\n",
    "    X_train, y_train, X_test, y_test = load_and_explore_data()\n",
    "    \n",
    "    # 2. Preprocess data\n",
    "    X_train, y_train, X_test, y_test = preprocess_data(X_train, y_train, X_test, y_test)\n",
    "    \n",
    "    # 3. Create data augmentation\n",
    "    data_augmentation = create_data_augmentation()\n",
    "    \n",
    "    # 4. Build model\n",
    "    model = build_model()\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    print(\"\\nModel Summary:\")\n",
    "    model.summary()\n",
    "    \n",
    "    # 5. Train model\n",
    "    print(\"\\nTraining model...\")\n",
    "    history = model.fit(\n",
    "        data_augmentation.flow(X_train, y_train, batch_size=32),\n",
    "        epochs=25,\n",
    "        validation_data=(X_test, y_test),\n",
    "        callbacks=create_callbacks(),\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # 6. Plot training history\n",
    "    plot_training_history(history)\n",
    "    \n",
    "    # 7. Evaluate model\n",
    "    print(\"\\nEvaluating model...\")\n",
    "    evaluate_model(model, X_test, y_test)\n",
    "    \n",
    "    # 8. Save model\n",
    "    print(\"\\nSaving model...\")\n",
    "    model.save('mnist_cnn_model.h5')\n",
    "    print(\"Model saved as 'mnist_cnn_model.h5'\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model loaded successfully.\n",
      "1/1 [==============================] - 0s 172ms/step\n",
      "\n",
      "Predictions for the first 5 digits in the test dataset:\n",
      "Sample 1: Predicted: 7, True Label: 7\n",
      "Sample 2: Predicted: 2, True Label: 2\n",
      "Sample 3: Predicted: 1, True Label: 1\n",
      "Sample 4: Predicted: 0, True Label: 0\n",
      "Sample 5: Predicted: 4, True Label: 4\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 9. Test Model Performance\n",
    "def test_model_performance(model, X_test, y_test):\n",
    "    # Get predictions for the first 5 test samples\n",
    "    predictions = model.predict(X_test[:5])\n",
    "    \n",
    "    # Convert predictions and true labels from one-hot encoding to class labels\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "    true_classes = np.argmax(y_test[:5], axis=1)\n",
    "    \n",
    "    # Print predicted and true classes\n",
    "    print(\"\\nPredictions for the first 5 digits in the test dataset:\")\n",
    "    for i in range(5):\n",
    "        print(f\"Sample {i+1}: Predicted: {predicted_classes[i]}, True Label: {true_classes[i]}\")\n",
    "    \n",
    "    # Plot the first 5 test samples with their predicted labels\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    for i in range(5):\n",
    "        plt.subplot(1, 5, i+1)\n",
    "        plt.imshow(X_test[i].reshape(28, 28), cmap='gray')\n",
    "        plt.title(f\"Pred: {predicted_classes[i]}\")\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('first_5_predictions.png')\n",
    "    plt.show()\n",
    "\n",
    "# 10. Loading the saved model and testing it\n",
    "def load_and_test_model():\n",
    "    # Load the trained model\n",
    "    model = tf.keras.models.load_model('mnist_cnn_model.h5')\n",
    "    print(\"\\nModel loaded successfully.\")\n",
    "    \n",
    "    # Load the MNIST test data (same as when we trained)\n",
    "    (_, _), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "    \n",
    "    # Preprocess the data\n",
    "    X_test = X_test.astype('float32') / 255\n",
    "    X_test = X_test.reshape((-1, 28, 28, 1))\n",
    "    y_test = to_categorical(y_test, 10)\n",
    "    \n",
    "    # Test model performance\n",
    "    test_model_performance(model, X_test, y_test)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    load_and_test_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mnist_cnn_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
